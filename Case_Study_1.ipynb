{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "# LIBRARY IMPORTS#\n",
    "###################\n",
    "import twitter\n",
    "import json\n",
    "import os\n",
    "import collections\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from sys import maxsize\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from urllib.error import URLError\n",
    "from http.client import BadStatusLine\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "# CUSTOM FUNCTIONS#\n",
    "###################\n",
    "\n",
    "#########################################################################\n",
    "#TAKES RAW TWITTER DATA AND PRINTS JSON#\n",
    "##################  START   #######################################################\n",
    "def pp(invar):\n",
    "    f= json.dumps(invar, indent=1)\n",
    "    print(f)\n",
    "##################   END    ##########################################\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "#CONNECT TO TWITTER API####\n",
    "##################  START   ############################################\n",
    "def oauth():\n",
    "    CONSUMER_KEY = redacted\n",
    "    CONSUMER_SECRET =redacted\n",
    "    OAUTH_TOKEN = redacted\n",
    "    OAUTH_TOKEN_SECRET = redacted\n",
    "\n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api\n",
    "####################  END  ##################################################\n",
    "\n",
    "#####################################################################\n",
    "#KEYWORD SEARCH\n",
    "#q=keyword\n",
    "#count\n",
    "##################  START   ############################################\n",
    "def twitter_search(q, count, twitter_api, **kw):\n",
    "    \n",
    "    search_results = twitter_api.search.tweets(q=q, count=count)\n",
    "    statuses = search_results['statuses']\n",
    "\n",
    "    for _ in range(10):\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_results']\n",
    "        except KeyError: # No more results when next_results doesn't exist\n",
    "            break\n",
    "\n",
    "        kwargs = dict([ kv.split('=') \n",
    "            for kv in next_results[1:].split(\"&\") ])\n",
    "    \n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "    return statuses\n",
    "###################  END  ##################################################\n",
    "\n",
    "#####################################################################\n",
    "#EXPORT JSON FILE\n",
    "#invar=variable containing data to be converted to json\n",
    "#filename=file name for the json data to be save to\n",
    "##################  START   ############################################\n",
    "def json_export(invar, filename):\n",
    "    data = json.dumps(invar, indent=1)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "###################  END  ##################################################\n",
    "\n",
    "#####################################################################\n",
    "#AGGREGATE RESULTS FROM ALL TXT FILES IN RAW TWEETS FOLDER\n",
    "#path=path for the raw tweets\n",
    "##################  START   ############################################\n",
    "def agg_results():\n",
    "    cwd = os.getcwd()\n",
    "    path = cwd + \"\\\\rawtweets\" # change \\\\ to / if running on Mac computer\n",
    "    files = os.listdir(path)\n",
    "    agg_raw_data = []\n",
    "    \n",
    "    for infile in files:\n",
    "        print(infile)\n",
    "        filename = path + \"\\\\\" + infile # change \\\\ to / if running on Mac computer\n",
    "        print(filename)\n",
    "        with open(filename) as raw_data:\n",
    "            raw_data = json.load(raw_data)\n",
    "        agg_raw_data += raw_data\n",
    "    return(agg_raw_data)\n",
    "###################  END  ##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "################        MAIN FUNCTIOn   ############################\n",
    "\n",
    "# twitter_api = oauth()\n",
    "# search = ['bitcoin','XRP','etherium','litecoin','namecoin']\n",
    "# result = []\n",
    "# filename = 'Export.txt'\n",
    "# cwd = os.getcwd()\n",
    "# path = cwd\n",
    "# for i in search:\n",
    "#        result += twitter_search(i, 1000, twitter_api)\n",
    "# json_export(result, filename)\n",
    "\n",
    "results = agg_results()\n",
    "json_export(results, \"all_tweets.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8527\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "# converts .txt file into json structure\n",
    "file = \"all_tweets.txt\"\n",
    "with open(file) as raw_data:\n",
    "    parsed_data = json.load(raw_data)\n",
    "\n",
    "# finds indices of repeated tweets\n",
    "texts = []\n",
    "repeated_indices = []\n",
    "for index in range(len(parsed_data)):\n",
    "    text = parsed_data[index]['text']\n",
    "    if text in texts:\n",
    "        repeated_indices.append(index)\n",
    "    else:\n",
    "        texts.append(text)\n",
    "\n",
    "# deletes repeated tweets\n",
    "for index in sorted(repeated_indices, reverse = True): \n",
    "    del parsed_data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Words         Count\n",
      "--------------  -------\n",
      "https              5173\n",
      "co                 5017\n",
      "bitcoin            3375\n",
      "xrp                2690\n",
      "namecoin           2372\n",
      "btc                2278\n",
      "rt                 2183\n",
      "1                  2101\n",
      "usd                1943\n",
      "0                  1851\n",
      "litecoin           1816\n",
      "eth                1645\n",
      "ltc                1442\n",
      "cryptocurrency     1412\n",
      "ripple             1147\n",
      "etherium           1051\n",
      "30                  880\n",
      "mins                809\n",
      "nmc                 787\n",
      "ethereum            735\n",
      "etc                 700\n",
      "price               699\n",
      "dash                634\n",
      "neo                 629\n",
      "crypto              572\n",
      "blockchain          553\n",
      "market              491\n",
      "changed             443\n",
      "omg                 434\n",
      "bch                 412\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def top30words(json_tweet_data):\n",
    "    # gathers the text from each tweet into a list, all converted to lowercase\n",
    "    all_tweets = []\n",
    "    for tweet in json_tweet_data:\n",
    "        all_tweets.append(tweet['text'].lower())\n",
    "    \n",
    "    # counts the number of words in each tweet's text\n",
    "    bag_of_words = [collections.Counter(re.findall(r'\\w+', text)) for text in all_tweets]\n",
    "    # collects all words and word counts together\n",
    "    bags_sum = sum(bag_of_words, collections.Counter())\n",
    "    \n",
    "    # loads English stopwords and removes them from bag of words\n",
    "    with open(\"stopwords/english\") as file:\n",
    "        stopword_list = file.readlines()\n",
    "    stopword_list = [newline.strip() for newline in stopword_list] \n",
    "    for stopword in stopword_list:\n",
    "        if stopword in bags_sum:\n",
    "            del bags_sum[stopword]\n",
    "            \n",
    "    # prints table of top 30 words and their counts\n",
    "    print(tabulate(bags_sum.most_common(30), headers=['Top Words', 'Count']))\n",
    "    print(\"\\n\")\n",
    "\n",
    "top30words(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mCount\tTop Tweets\u001b[0m\n",
      "\n",
      "34169\t\"RT @lorde: VOGUE BABY AHHH! ‚ú®üçå‚ò∫Ô∏è https://t.co/pxHDeyeFhd\"\n",
      "28713\t\"RT @stem910: ÂÖàÊó•È†≠„ÅÆ„ÅÑ„ÅÑÂèã‰∫∫„Å´„ÄåÂñã„ÇäÊñπ„Åå„Éê„Ç´„Å£„ÅΩ„ÅÑ„ÅÆ„Çí„Å™„Çì„Å®„Åã„Åó„Åü„ÅÑ„Äç„Å®Áõ∏Ë´á„Åó„Åü„Çâ„Äå„Éê„Ç´„Å£„ÅΩ„ÅÑ„Å®„ÅÑ„ÅÜ„ÅÆ„ÅØÊú¨ÂΩì„ÅØ„Éê„Ç´„Åß„ÅØ„Å™„ÅÑ„ÅÆ„Å´„Éê„Ç´„Å®ÊÄù„Çè„Çå„Å¶„Åó„Åæ„ÅÜ„Å®„ÅÑ„ÅÜ„Åì„Å®„Å†„Åå„ÄÅ„ÅäÂâç„ÅØ‰∫ãÂÆü„Éê„Ç´„Å†„Çç„Äç„Å®ÊåáÊëò„Åï„Çå„Åü„ÅÆ„Åß„Äå„Å™„ÇãÁ®ã„ÄÇ„Åß„ÅØ„Éê„Ç´„ÇíÂº∑Ë™ø„Åô„ÇãÂñã„ÇäÊñπ„Çí„ÇÑ„ÇÅ„Åü„ÅÑ„Äç„Å®Áõ∏Ë´á„ÅóÁõ¥„Åó„Åü„Çâ‚Äú„ÅÇ‚Ä¶\"\n",
      "14256\t\"RT @tsumland_jp: ‚ú®ÊúÄÂ§ß100‰∏áÂÜÜÂàÜ„ÅÆÊµ∑Â§ñ„Éá„Ç£„Ç∫„Éã„ÉºÊóÖË°å„ÅåÂΩì„Åü„Çã„Åã„ÇÇ‚ú®\n",
      "„Éá„Ç£„Ç∫„Éã„Éº „ÉÑ„É†„ÉÑ„É†„É©„É≥„Éâ„ÅÆ‰∫ãÂâçÁôªÈå≤„Ç≠„É£„É≥„Éö„Éº„É≥„ÇíÂÆüÊñΩ‰∏≠ÔºÅ\n",
      "„Åì„ÅÆ„Ç¢„Ç´„Ç¶„É≥„Éà„Çí„Éï„Ç©„É≠„Éº„Åô„Çã„Å†„Åë„ÅßË±™ËèØË≥ûÂìÅ„ÅåÂΩì„Åü„Çã„ÉÅ„É£„É≥„Çπüéµ\n",
      "„Åì„ÅÆÊ©ü‰ºö„Çí„ÅäË¶ãÈÄÉ„Åó„Å™„Åè‚òÜ ÔºÉ„ÉÑ„É†„ÉÑ„É†„É©„É≥„Éâ\n",
      "Ë©≥Á¥∞‚Üì\n",
      "https://‚Ä¶\"\n",
      "7079\t\"RT @aco220: ÂèãÈÅî„Åå„ÄåÂΩºÊ∞è„Å®Âà•„Çå„Åù„ÅÜ„Äç„Å£„Å¶Ë®Ä„ÅÜ„Åã„Çâ„ÄÅ‰Ωï‰∫ã„Å†‰Ωï„Åå„ÅÇ„Å£„Åü„ÅÆ„Åã„Å©„ÅÜ„Åó„Åü„ÅÆ„Åã„Å£„Å¶ËÅû„ÅÑ„Åü„Çâ„ÄÅ„ÄåExcel„Åß‰∏ã„Å´„Åö„Çâ„Åó„Å¶Êï∞Â≠ó„Åå‰∏¶„Å∂„ÅÆÁü•„Çâ„Å™„ÅÑ‰∫∫„Å®„ÅØ‰ªò„ÅçÂêà„Åà„Å™„ÅÑ„Äç„Å£„Å¶„ÄÅ„Ç™„Éº„Éà„Éï„Ç£„É´„Çè„Åã„Çì„Å™„ÅÑ„Å®„Éï„É©„Çå„Çã„ÅÆ„ÇÑ„Å∞„ÅÑ„Å™\"\n",
      "5978\t\"RT @emartineeez: RT THIS TWEET IF YOU WANT TWO VIDEOS TODAYüòÅ\"\n",
      "5651\t\"RT @at_raku: Êù±‰∫¨„Éâ„Éº„É†„Ç∑„ÉÜ„Ç£ „Ç¢„Éà„É©„ÇØ„Ç∑„Éß„É≥„Ç∫„Åß„ÅØ„ÄÅ9/30ÔºàÂúüÔºâ~„ÄåÊ¥ªÊíÉ ÂàÄÂâ£‰π±Ëàû„Äç„Å®„ÅÆ„Ç≥„É©„Éú„Ç§„Éô„É≥„Éà„ÄéÂá∫Èô£ÔºÅÊ¥ªÊíÉ ÂàÄÂâ£‰π±Ëàû in Êù±‰∫¨„Éâ„Éº„É†„Ç∑„ÉÜ„Ç£„Äè„ÇíÈñãÂÇ¨ÔºÅÈôêÂÆö„ÇØ„É™„Ç¢„Éï„Ç°„Ç§„É´„ÅåË≤∞„Åà„Çã„Çπ„Çø„É≥„Éó„É©„É™„Éº„ÄÅ„Ç≥„É©„Éú„Éï„Éº„Éâ&amp;„Ç∞„ÉÉ„Ç∫„ÇÇË≤©Â£≤ÔºÅhttps://t.co/KDW2‚Ä¶\"\n",
      "5604\t\"RT @ErikVoorhees: My memory is failing, was it Bitcoin or was it JP Morgan that was bailed out by the government? https://t.co/DHqFzr5UJN\"\n",
      "3828\t\"RT @huga731: #btc #bitcoin #xem #comsa #nem 100 000 —É–∂–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª–æ—Å—å –≤ –Ø–ø–æ–Ω—Å–∫–æ–º ico COMSA .–≠—Ç–æ –±—É–¥–µ—Ç —Å–∞–º–æ–µ –º–∞—Å—à—Ç–∞–±–Ω–æ–µ –∞–π—Å–∏–æüí™https://t‚Ä¶\"\n",
      "3244\t\"RT @imartinezp_: RETWEET MY LAST TWEET FOR A FOLLOW\"\n",
      "2864\t\"RT @RivetzCorp: Rivetz Enables Provable Cybersecurity #cryptocurrency #blockchain #ethereum #bitcoin #btc #bitcoins #ICO #token #crowdsale‚Ä¶\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "def top10retweeted(json_tweet_data):\n",
    "    # gathers number of retweet counts for each tweet into a list\n",
    "    retweet_counts = []\n",
    "    for tweet in json_tweet_data:\n",
    "        retweet_counts.append(tweet['retweet_count'])\n",
    "\n",
    "    # finds indices of top 10 retweet counts, ordered from most to least\n",
    "    top10indices = sorted(range(len(retweet_counts)), key = lambda i: retweet_counts[i])[:-11:-1]\n",
    "    \n",
    "    # prints table of top 10 tweets and their retweet counts\n",
    "    print(\"\\033[4mCount\\tTop Tweets\\033[0m\\n\")\n",
    "    for index in top10indices:\n",
    "        print(str(json_tweet_data[index]['retweet_count']) + \"\\t\\\"\" + json_tweet_data[index]['text'] + \"\\\"\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "top10retweeted(parsed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 hashtags, top 10 user mentions that are the most popular in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Hashtags       Count\n",
      "---------------  -------\n",
      "#bitcoin            1188\n",
      "#cryptocurrency     1180\n",
      "#namecoin            737\n",
      "#nmc                 708\n",
      "#Bitcoin             687\n",
      "#litecoin            567\n",
      "#etherium            475\n",
      "#Litecoin            421\n",
      "#XRP                 376\n",
      "#xrp                 352\n",
      "\n",
      "\n",
      "Top Users Mentioned      Count\n",
      "---------------------  -------\n",
      "@Ripple                    125\n",
      "@Keiki_XRP                 116\n",
      "@cryptopayments2            71\n",
      "@erishiiiii                 71\n",
      "@SatoshiLite                69\n",
      "@TO30447473                 68\n",
      "@toyokichimaru              66\n",
      "@cannavinothc               59\n",
      "@MarketNmc                  51\n",
      "@cryptographicc             49\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "def top10hashtags_user_mentions(json_tweet_data):\n",
    "    user_list = []\n",
    "    hashtag_list = []\n",
    "    \n",
    "    for tweet in json_tweet_data:\n",
    "        # gathers the hashtags from each tweet into a list\n",
    "        hashtags = tweet['entities']['hashtags']\n",
    "        if len(hashtags):\n",
    "            for hashtag in hashtags:\n",
    "                hashtag_list.append(\"#\" + hashtag['text'])\n",
    "        \n",
    "        # gathers the users mentioned in each tweet into a list\n",
    "        user_mentions = tweet['entities']['user_mentions']\n",
    "        if len(user_mentions):\n",
    "            for user in user_mentions:\n",
    "                user_list.append(\"@\" + user['screen_name'])\n",
    "\n",
    "    # counts number of each hashtag\n",
    "    hashtag_count = collections.Counter(hashtag_list)\n",
    "    # prints table of top 10 hashtags with their counts\n",
    "    print(tabulate(hashtag_count.most_common(10), headers=['Top Hashtags', 'Count']))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # counts number of times each user is mentioned\n",
    "    user_count = collections.Counter(user_list)\n",
    "    # prints table of top 10 users mentioned and their counts\n",
    "    print(tabulate(user_count.most_common(10), headers=['Top Users Mentioned', 'Count']))\n",
    "    \n",
    "top10hashtags_user_mentions(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Friends ID Friends Screen name\n",
      "0   812491802955644928      EmbermineDrake\n",
      "1   797930343277989888        TheEmbermine\n",
      "2            104259801         Squidoogeek\n",
      "3            262755165     SkinnerLiber8ed\n",
      "4   788886561731538944              YVerif\n",
      "5   902772556670914560          VUnioninfo\n",
      "6           1479248557        msjemmagreen\n",
      "7           4341007829           uquidcard\n",
      "8   897380780510502912       CryptoTickets\n",
      "9           2309343738     OfficialTitcoin\n",
      "10  888615399281102848     GoldenFleece_co\n",
      "11          2600194316         NewKoreCoin\n",
      "12          1664012648       chimaera_tech\n",
      "13          2313671966         NEMofficial\n",
      "14           221071894              drbitq\n",
      "15  867574261195522048           matryx_ai\n",
      "16  873598891723239424          BlockDevCo\n",
      "17  769176690908069888       godzillion_io\n",
      "18  775658150179508224              iEx_ec\n",
      "19  857130360903274500         Bitcore_BTX\n",
      "\n",
      "\n",
      "          Followers ID Followers Screen name\n",
      "0   910877157651394560           AjayBan7014\n",
      "1            130300297             Luebbello\n",
      "2            356323836               TomAL84\n",
      "3            172217323             fanyeeezy\n",
      "4            233046320         Muhammadyarpk\n",
      "5   896600481740406784       Bitcointrader71\n",
      "6   886594406257741826           ANA_Anacoin\n",
      "7   910412463799123968            miyazakico\n",
      "8           3662372061             RawITnews\n",
      "9            462849193             RuudHolla\n",
      "10  721824974906916864           adnarimjoel\n",
      "11          1598911699         jetjaguar3030\n",
      "12          2233501680               luishut\n",
      "13          2460243694           mistertapps\n",
      "14  890289232484466688           YohannesGee\n",
      "15  905865817501429761            coolix1254\n",
      "16           886367528                 vrdci\n",
      "17  899895351641088000        trader_altcoin\n",
      "18  907853605855744000            Mikey105uk\n",
      "19           142529167            elpablo090\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "CONSUMER_KEY = redacted\n",
    "CONSUMER_SECRET =redacted\n",
    "OAUTH_TOKEN = redacted\n",
    "OAUTH_TOKEN_SECRET = redacted\n",
    "\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                       CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter_api = twitter.Twitter(auth=auth)\n",
    "#Start: Creating authorization for tweepy\n",
    "auth1 = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "auth1.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "\n",
    "\n",
    "tweepy_api=tweepy.API(auth1,wait_on_rate_limit=True)\n",
    "# End: Creating authorization for tweepy\n",
    "\n",
    "#Start : Method to plot ID & Screen_name of 20 friends of any user\n",
    "def plot_user_friends(popular_user) :\n",
    "    friend_ids=[]\n",
    "    friend_names=[]\n",
    "    user = tweepy_api.get_user(popular_user)\n",
    "    friend_list = user.friends()\n",
    "    for friend in friend_list :\n",
    "        friend_ids.append(friend.id_str)\n",
    "        friend_names.append(friend.screen_name)\n",
    "    friends_df = pd.DataFrame({\"Friends ID\": friend_ids, \"Friends Screen name\":friend_names })\n",
    "    print(friends_df)\n",
    "    \n",
    "#End : Method to plot ID & Screen_name of 20 friends of any user\n",
    "\n",
    "#Start : Method to plot ID & Screen_name of 20 followers of any user\n",
    "\n",
    "def plot_user_followers(popular_user) :\n",
    "    followers_ids=[]\n",
    "    followers_names=[]\n",
    "    user = tweepy_api.get_user(popular_user)\n",
    "    followers_list = user.followers()\n",
    "    for follower in followers_list :\n",
    "        followers_ids.append(follower.id_str)\n",
    "        followers_names.append(follower.screen_name)\n",
    "    followers_df = pd.DataFrame({\"Followers ID\": followers_ids, \"Followers Screen name\":followers_names })\n",
    "    print(followers_df)   \n",
    "    \n",
    "#End : Method to plot ID & Screen_name of 20 followers of any user\n",
    "\n",
    "plot_user_friends('cryptocointalk')\n",
    "print(\"\\n\")\n",
    "plot_user_followers('cryptocointalk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "import tweepy\n",
    "import time\n",
    "import tweepy.error\n",
    "from requests.exceptions import Timeout, ConnectionError\n",
    "from requests.packages.urllib3.exceptions import ReadTimeoutError\n",
    "import pandas as pd\n",
    "\n",
    "# Creating variables to be used throughout the code\n",
    "friends_list=[] \n",
    "friends_ids=[]\n",
    "followers_list=[]\n",
    "followers_ids=[]\n",
    "\n",
    "# Start : Set authorisation for connection to Twitter & Tweepy api\n",
    "\n",
    "CONSUMER_KEY = redacted\n",
    "CONSUMER_SECRET =redacted\n",
    "OAUTH_TOKEN = redacted\n",
    "OAUTH_TOKEN_SECRET = redacted\n",
    "\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                       CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth1 = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "auth1.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "\n",
    "api=tweepy.API(auth1,wait_on_rate_limit=True)\n",
    "\n",
    "# End : Set authorisation for connection to Twitter & Tweepy api\n",
    "\n",
    "# Start : Function to get list of all friends of a user i.e. 'cryptocointalk' & store it in a text file\n",
    "def get_friends():\n",
    "    i=0\n",
    "    j=0\n",
    "    f = open('Friends_list.txt', 'w')\n",
    "    users=tweepy.Cursor(api.friends, screen_name=\"cryptocointalk\",count=200).items()\n",
    "    while True:\n",
    "            try:\n",
    "                j=j+1\n",
    "                user=next(users)\n",
    "                i=i+1\n",
    "                friends_list.append(user.screen_name)\n",
    "                friends_ids.append(user.id)\n",
    "                f.write(user.screen_name+'\\n')\n",
    "                if j>2900:\n",
    "                    j=0\n",
    "                    time.sleep(15*60)\n",
    "            except (tweepy.TweepError) as ex:\n",
    "                time.sleep(60*16)\n",
    "                pass\n",
    "            except (StopIteration):\n",
    "                break\n",
    "\n",
    "\n",
    "# End : Function to get list of all friends of a user i.e. 'cryptocointalk' & store it in a text file   \n",
    "\n",
    "# Start : Function to get list of all followers of a user i.e. 'cryptocointalk' & store it in a text file\n",
    "def get_followers():\n",
    "    i=0\n",
    "    j=0\n",
    "    f = open('Followers_list.txt', 'w')\n",
    "    users=tweepy.Cursor(api.followers, screen_name=\"cryptocointalk\",count=200).items()\n",
    "    while True:\n",
    "            try:\n",
    "                j=j+1\n",
    "                user=next(users)\n",
    "                i=i+1\n",
    "                followers_list.append(user.screen_name)\n",
    "                followers_ids.append(user.id)\n",
    "                f.write(user.screen_name+'\\n')\n",
    "                if j>2900:\n",
    "                    break\n",
    "                    j=0\n",
    "                    time.sleep(15*60)\n",
    "            except (tweepy.TweepError) as ex:\n",
    "                time.sleep(60*16)\n",
    "                pass\n",
    "            except (StopIteration):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<twitter.api.Twitter object at 0x117fc4dd8>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetched 1000 total friends ids for cryptocointalk\n",
      "Fetched 5000 total followers ids for cryptocointalk\n",
      "Fetched 10000 total followers ids for cryptocointalk\n",
      "Fetched 15000 total followers ids for cryptocointalk\n",
      "Fetched 20000 total followers ids for cryptocointalk\n",
      "Fetched 25000 total followers ids for cryptocointalk\n",
      "Fetched 29731 total followers ids for cryptocointalk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cryptocointalk has 996 mutual friends\n",
      "              Mutual ID Mutual Screen name\n",
      "0    812491802955644928     EmbermineDrake\n",
      "1    797930343277989888       TheEmbermine\n",
      "2    788886561731538944             YVerif\n",
      "3    902772556670914560         VUnioninfo\n",
      "4    897380780510502912      CryptoTickets\n",
      "5    888615399281102848    GoldenFleece_co\n",
      "6    867574261195522048          matryx_ai\n",
      "7    873598891723239424         BlockDevCo\n",
      "8    769176690908069888      godzillion_io\n",
      "9    775658150179508224             iEx_ec\n",
      "10   857130360903274500        Bitcore_BTX\n",
      "11   874241762075832322       mindpass2050\n",
      "12   848547538957328387     bonzocorleonee\n",
      "13   867498616730025985          HonestisN\n",
      "14   867456902627721218     QchainPlatform\n",
      "15   824342681912561678    MARXCOLLECTIVE1\n",
      "16   862041575081246723       CONTENT_COIN\n",
      "17            274456588      cryptocoinfan\n",
      "18           2335207442          coinshost\n",
      "19           3662979086        customminer\n",
      "20             43192340           JackPhan\n",
      "21           2150123534            newsbtc\n",
      "22             17186834            djspang\n",
      "23             42584086            siavash\n",
      "24            240633881          BenBschor\n",
      "25           1950640170      joebitcoinorg\n",
      "26            204265518        umutkatirci\n",
      "27            124192816         philvadala\n",
      "28             14778418      tophermallory\n",
      "29            134234167            moeager\n",
      "..                  ...                ...\n",
      "966          2949656521      XBTFreelancer\n",
      "967          3264958412        bitcointens\n",
      "968          2200360908      Bitcoin_Ideas\n",
      "969          3972972494       OKcashOrator\n",
      "970            31289296          dandidier\n",
      "971          2375624659        LegendsRoom\n",
      "972            13879252           matty990\n",
      "973          3523307477           ICOviral\n",
      "974          2433495000     NiceHashMining\n",
      "975            87494620        GigaBitcoin\n",
      "976            15917024            DETHTRP\n",
      "977           243300322      babs_presents\n",
      "978          2370355171     Beyond_Bitcoin\n",
      "979           143116260       sergeysholom\n",
      "980          3995942885     cryptodesigneu\n",
      "981          1649055714    WorldcoinGlobal\n",
      "982          2295386088          JStuhlman\n",
      "983          1652768744            GMCoins\n",
      "984           126916586              sirxl\n",
      "985          2492063724            _CFour_\n",
      "986          2595164142      VeryVeriViral\n",
      "987           322129904         CryptoRave\n",
      "988          2204033010      CureCoin_Team\n",
      "989          2832500723       EricRSammons\n",
      "990            28919797      shin_novation\n",
      "991          2688509941      SuprnovaPools\n",
      "992            27760633            ILCoins\n",
      "993           193030139      eric_kavanagh\n",
      "994          2203045884          DirtDOLLA\n",
      "995          2832697342       OliverDurrer\n",
      "\n",
      "[996 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Code to fetch list of mutual friends\n",
    "\n",
    "CONSUMER_KEY = redacted\n",
    "CONSUMER_SECRET =redacted\n",
    "OAUTH_TOKEN = redacted\n",
    "OAUTH_TOKEN_SECRET = redacted\n",
    "\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "twitter_api = twitter.Twitter(auth=auth)\n",
    "\n",
    "auth1 = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "auth1.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "\n",
    "api=tweepy.API(auth1,wait_on_rate_limit=True)\n",
    "\n",
    "print(twitter_api)\n",
    "\n",
    "\n",
    "\n",
    "def make_twitter_request(twitter_api_func, max_errors=10, *args, **kw): \n",
    "    \n",
    "    # A nested helper function that handles common HTTPErrors. Return an updated\n",
    "    # value for wait_period if the problem is a 500 level error. Block until the\n",
    "    # rate limit is reset if it's a rate limiting issue (429 error). Returns None\n",
    "    # for 401 and 404 errors, which requires special handling by the caller.\n",
    "    def handle_twitter_http_error(e, wait_period=2, sleep_when_rate_limited=True):\n",
    "    \n",
    "        if wait_period > 3600: # Seconds\n",
    "            print('Too many retries. Quitting.', file=sys.stderr)\n",
    "            raise e\n",
    "    \n",
    "        # See https://dev.twitter.com/docs/error-codes-responses for common codes\n",
    "    \n",
    "        if e.e.code == 401:\n",
    "            print('Encountered 401 Error (Not Authorized)', file=sys.stderr)\n",
    "            return None\n",
    "        elif e.e.code == 404:\n",
    "            print('Encountered 404 Error (Not Found)', file=sys.stderr)\n",
    "            return None\n",
    "        elif e.e.code == 429: \n",
    "            print('Encountered 429 Error (Rate Limit Exceeded)', file=sys.stderr)\n",
    "            if sleep_when_rate_limited:\n",
    "                print(\"Retrying in 15 minutes...ZzZ...\", file=sys.stderr)\n",
    "                sys.stderr.flush()\n",
    "                time.sleep(60*15 + 5)\n",
    "                print('...ZzZ...Awake now and trying again.', file=sys.stderr)\n",
    "                return 2\n",
    "            else:\n",
    "                raise e # Caller must handle the rate limiting issue\n",
    "        elif e.e.code in (500, 502, 503, 504):\n",
    "            print('Encountered %i Error. Retrying in %i seconds' % \\\n",
    "                (e.e.code, wait_period), file=sys.stderr)\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            return wait_period\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # End of nested helper function\n",
    "    \n",
    "    wait_period = 2 \n",
    "    error_count = 0 \n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            return twitter_api_func(*args, **kw)\n",
    "        except twitter.api.TwitterHTTPError as e:\n",
    "            error_count = 0 \n",
    "            wait_period = handle_twitter_http_error(e, wait_period)\n",
    "            if wait_period is None:\n",
    "                return\n",
    "        except URLError as e:\n",
    "            error_count += 1\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            print(\"URLError encountered. Continuing.\", file=sys.stderr)\n",
    "            if error_count > max_errors:\n",
    "                print(\"Too many consecutive errors...bailing out.\", file=sys.stderr)\n",
    "                raise\n",
    "        except BadStatusLine as e:\n",
    "            error_count += 1\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            print(\"BadStatusLine encountered. Continuing.\", file=sys.stderr)\n",
    "            if error_count > max_errors:\n",
    "                print(\"Too many consecutive errors...bailing out.\", file=sys.stderr)\n",
    "                raise\n",
    "                \n",
    "def get_friends_followers_ids(twitter_api, screen_name=None, user_id=None,\n",
    "                              friends_limit=maxsize, followers_limit=maxsize):\n",
    "    assert (screen_name != None) != (user_id != None)\n",
    "    get_friends_ids = partial(make_twitter_request, twitter_api.friends.ids, \n",
    "                              count=5000)\n",
    "    get_followers_ids = partial(make_twitter_request, twitter_api.followers.ids, \n",
    "                                count=5000)\n",
    "    friends_ids, followers_ids = [], []\n",
    "    \n",
    "    for twitter_api_func, limit, ids, label in [\n",
    "                    [get_friends_ids, friends_limit, friends_ids, \"friends\"], \n",
    "                    [get_followers_ids, followers_limit, followers_ids, \"followers\"]\n",
    "                ]:\n",
    "        \n",
    "        if limit == 0: continue\n",
    "        \n",
    "        cursor = -1\n",
    "        while cursor != 0:\n",
    "        \n",
    "            # Use make_twitter_request via the partially bound callable...\n",
    "            if screen_name: \n",
    "                response = twitter_api_func(screen_name=screen_name, cursor=cursor)\n",
    "            else: # user_id\n",
    "                response = twitter_api_func(user_id=user_id, cursor=cursor)\n",
    "\n",
    "            if response is not None:\n",
    "                ids += response['ids']\n",
    "                cursor = response['next_cursor']\n",
    "        \n",
    "            print('Fetched {0} total {1} ids for {2}'.format(len(ids), \n",
    "                                                    label, (user_id or screen_name)), file=sys.stderr)\n",
    "        \n",
    "            # XXX: You may want to store data during each iteration to provide an \n",
    "            # an additional layer of protection from exceptional circumstances\n",
    "        \n",
    "            if len(ids) >= limit or response is None:\n",
    "                break\n",
    "\n",
    "    return friends_ids[:friends_limit], followers_ids[:followers_limit]\n",
    "\n",
    "\n",
    "friends_ids, followers_ids = get_friends_followers_ids(twitter_api, \n",
    "                                                       screen_name=\"cryptocointalk\", \n",
    "                                                       friends_limit=100000000000000000000000, \n",
    "                                                       followers_limit=100000000000000000000000)\n",
    "\n",
    "\n",
    "\n",
    "friends_ids, followers_ids = set(friends_ids), set(followers_ids)\n",
    "print('{0} has {1} mutual friends'.format('cryptocointalk', len(friends_ids.intersection(followers_ids))))\n",
    "\n",
    "# get common followers & friends ids & store it in a list called result\n",
    "result = []\n",
    "for element in friends_ids:\n",
    "    if element in followers_ids:\n",
    "        result.append(element)\n",
    "\n",
    "\n",
    "# Store mutual friends & followers in a dataframe & display it\n",
    "\n",
    "mutual_friends_id = []\n",
    "mutual_friends_names = []\n",
    "for mutual in result :\n",
    "    mutual_friends_id.append(mutual)\n",
    "    mutual_friends_names.append(api.get_user(mutual).screen_name)\n",
    "    \n",
    "mutual_df = pd.DataFrame({\"Mutual ID\": mutual_friends_id, \"Mutual Screen name\":mutual_friends_names })\n",
    "print(mutual_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/renswny/Code/GitHub/DS501/rawtweets\n",
      "['results_091317_12PM.txt', 1968, 576, 0.507860273587814, 0.4269610414662494, 103, -0.30785510269126803, 0.5390088296277613, 1288, 0.3863430420711973]\n",
      "['results_091417_12PM.txt', 2040, 415, 0.3762832602053242, 0.5116602296632412, 93, -0.2770647803510707, 0.5007185690653437, 1531, 0.42889784946236537]\n",
      "['results_091417_19.txt', 1688, 289, 0.3621229306395019, 0.4949375177878632, 107, -0.2850366972774976, 0.5403104186398582, 1291, 0.3822541165999109]\n",
      "['results_091417_7PM.txt', 1688, 289, 0.3621229306395019, 0.4949375177878632, 107, -0.2850366972774976, 0.5403104186398582, 1291, 0.3822541165999109]\n",
      "['results_091417_9AM.txt', 3162, 695, 0.3439175176633585, 0.4682033014281221, 176, -0.24354205304999876, 0.46386171225659845, 2290, 0.3450487012987012]\n",
      "['results_091517_12PM.txt', 2917, 601, 0.3975863140381918, 0.5278367373521283, 207, -0.270254488599805, 0.4756835839504928, 2108, 0.2559983896940417]\n",
      "['results_091517_7PM.txt', 1560, 459, 0.3149888965125902, 0.41214321474942384, 92, -0.23479768218898653, 0.4215003092720485, 1008, 0.3279438405797102]\n",
      "['results_091517_9AM.txt', 1874, 303, 0.3671178814310001, 0.5316019161439957, 123, -0.30434350539001537, 0.4838184600328913, 1447, 0.3191202090592334]\n",
      "['results_091617_1030AM.txt', 1615, 353, 0.372325603515936, 0.5170509434694979, 92, -0.201023553740945, 0.39213764798003903, 1169, 0.3274585921325052]\n",
      "['results_091617_7PM.txt', 848, 267, 0.41167847414757547, 0.5511465164395872, 51, -0.23611063228710275, 0.41335649644473155, 529, 0.3319911297852475]\n",
      "['results_091717_8AM.txt', 1727, 292, 0.3398415004579385, 0.5592940453128807, 67, -0.18677534461116546, 0.4325964596486981, 1367, 0.5768656716417911]\n",
      "['results_09617_1030AM.txt', 1615, 353, 0.372325603515936, 0.5170509434694979, 92, -0.201023553740945, 0.39213764798003903, 1169, 0.3274585921325052]\n",
      "['results_09617_7PM.txt', 848, 267, 0.41167847414757547, 0.5511465164395872, 51, -0.23611063228710275, 0.41335649644473155, 529, 0.3319911297852475]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['results_091317_12PM.txt',\n",
       "  1968,\n",
       "  576,\n",
       "  0.507860273587814,\n",
       "  0.4269610414662494,\n",
       "  103,\n",
       "  -0.30785510269126803,\n",
       "  0.5390088296277613,\n",
       "  1288,\n",
       "  0.3863430420711973],\n",
       " ['results_091417_12PM.txt',\n",
       "  2040,\n",
       "  415,\n",
       "  0.3762832602053242,\n",
       "  0.5116602296632412,\n",
       "  93,\n",
       "  -0.2770647803510707,\n",
       "  0.5007185690653437,\n",
       "  1531,\n",
       "  0.42889784946236537],\n",
       " ['results_091417_19.txt',\n",
       "  1688,\n",
       "  289,\n",
       "  0.3621229306395019,\n",
       "  0.4949375177878632,\n",
       "  107,\n",
       "  -0.2850366972774976,\n",
       "  0.5403104186398582,\n",
       "  1291,\n",
       "  0.3822541165999109],\n",
       " ['results_091417_7PM.txt',\n",
       "  1688,\n",
       "  289,\n",
       "  0.3621229306395019,\n",
       "  0.4949375177878632,\n",
       "  107,\n",
       "  -0.2850366972774976,\n",
       "  0.5403104186398582,\n",
       "  1291,\n",
       "  0.3822541165999109],\n",
       " ['results_091417_9AM.txt',\n",
       "  3162,\n",
       "  695,\n",
       "  0.3439175176633585,\n",
       "  0.4682033014281221,\n",
       "  176,\n",
       "  -0.24354205304999876,\n",
       "  0.46386171225659845,\n",
       "  2290,\n",
       "  0.3450487012987012],\n",
       " ['results_091517_12PM.txt',\n",
       "  2917,\n",
       "  601,\n",
       "  0.3975863140381918,\n",
       "  0.5278367373521283,\n",
       "  207,\n",
       "  -0.270254488599805,\n",
       "  0.4756835839504928,\n",
       "  2108,\n",
       "  0.2559983896940417],\n",
       " ['results_091517_7PM.txt',\n",
       "  1560,\n",
       "  459,\n",
       "  0.3149888965125902,\n",
       "  0.41214321474942384,\n",
       "  92,\n",
       "  -0.23479768218898653,\n",
       "  0.4215003092720485,\n",
       "  1008,\n",
       "  0.3279438405797102],\n",
       " ['results_091517_9AM.txt',\n",
       "  1874,\n",
       "  303,\n",
       "  0.3671178814310001,\n",
       "  0.5316019161439957,\n",
       "  123,\n",
       "  -0.30434350539001537,\n",
       "  0.4838184600328913,\n",
       "  1447,\n",
       "  0.3191202090592334],\n",
       " ['results_091617_1030AM.txt',\n",
       "  1615,\n",
       "  353,\n",
       "  0.372325603515936,\n",
       "  0.5170509434694979,\n",
       "  92,\n",
       "  -0.201023553740945,\n",
       "  0.39213764798003903,\n",
       "  1169,\n",
       "  0.3274585921325052],\n",
       " ['results_091617_7PM.txt',\n",
       "  848,\n",
       "  267,\n",
       "  0.41167847414757547,\n",
       "  0.5511465164395872,\n",
       "  51,\n",
       "  -0.23611063228710275,\n",
       "  0.41335649644473155,\n",
       "  529,\n",
       "  0.3319911297852475],\n",
       " ['results_091717_8AM.txt',\n",
       "  1727,\n",
       "  292,\n",
       "  0.3398415004579385,\n",
       "  0.5592940453128807,\n",
       "  67,\n",
       "  -0.18677534461116546,\n",
       "  0.4325964596486981,\n",
       "  1367,\n",
       "  0.5768656716417911],\n",
       " ['results_09617_1030AM.txt',\n",
       "  1615,\n",
       "  353,\n",
       "  0.372325603515936,\n",
       "  0.5170509434694979,\n",
       "  92,\n",
       "  -0.201023553740945,\n",
       "  0.39213764798003903,\n",
       "  1169,\n",
       "  0.3274585921325052],\n",
       " ['results_09617_7PM.txt',\n",
       "  848,\n",
       "  267,\n",
       "  0.41167847414757547,\n",
       "  0.5511465164395872,\n",
       "  51,\n",
       "  -0.23611063228710275,\n",
       "  0.41335649644473155,\n",
       "  529,\n",
       "  0.3319911297852475]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def agg_results(path):\n",
    "    cwd = os.getcwd()\n",
    "    path = cwd + \"\\\\rawtweets\" # change \\\\ to / if running on Mac computer\n",
    "    print(path)\n",
    "    files = os.listdir(path)\n",
    "    results = []\n",
    "    for infile in files:\n",
    "        all_tweets = []\n",
    "        filename=path + \"\\\\\" + infile # change \\\\ to / if running on Mac computer\n",
    "        with open(filename) as raw_data:\n",
    "            parsed_data = json.load(raw_data)\n",
    "            for tweet in parsed_data:\n",
    "                all_tweets.append(tweet['text'])\n",
    "            result = sentiment_cat(all_tweets,infile)\n",
    "            results.append(result)\n",
    "            print(result)\n",
    "    print_results(results, cwd + \"\\\\output_problem4.csv\") # change \\\\ to / if running on Mac computer\n",
    "    return(results)\n",
    "\n",
    "#####################################################################\n",
    "#SENTIMENT ANALYSIS\n",
    "#invar=variable containing data to be converted to json\n",
    "#filename=file name for the json data to be save to\n",
    "##################  START   ############################################\n",
    "def sentiment_cat(all_tweets,infile):\n",
    "    cntnodup = 0\n",
    "    poscnt = 0\n",
    "    pos_polar = 0\n",
    "    pos_subj = 0\n",
    "    negcnt = 0\n",
    "    neg_polar = 0 \n",
    "    neg_subj = 0 \n",
    "    neutcnt = 0 \n",
    "    neut_subj = 0\n",
    "    result = []\n",
    "    \n",
    "    cntnodup += 1\n",
    "    \n",
    "    for i in range(0, len(all_tweets) - 1):\n",
    "        cntnodup += 1\n",
    "        x = TextBlob(all_tweets[i])\n",
    "        if x.sentiment.polarity > 0:\n",
    "            poscnt += 1\n",
    "            pos_polar += x.sentiment.polarity\n",
    "            pos_subj += x.sentiment.subjectivity\n",
    "\n",
    "        elif x.sentiment.polarity == 0:\n",
    "            neutcnt += 1\n",
    "            neut_subj += x.sentiment.subjectivity\n",
    "\n",
    "        else:\n",
    "            negcnt += 1\n",
    "            neg_polar += x.sentiment.polarity \n",
    "            neg_subj += x.sentiment.subjectivity\n",
    "        \n",
    "    result.append(infile)\n",
    "    result.append(cntnodup)  \n",
    "    result.append(poscnt)\n",
    "    result.append(pos_polar / poscnt)  \n",
    "    result.append(pos_subj / poscnt)  \n",
    "    result.append(negcnt)  \n",
    "    result.append(neg_polar / negcnt)  \n",
    "    result.append(neg_subj / negcnt)  \n",
    "    result.append(neutcnt)  \n",
    "    result.append(neut_subj / negcnt)  \n",
    "    return(result)\n",
    "\n",
    "###################  END  ##################################################\n",
    "def print_results(output, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(output)\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "################        MAIN FUNCTIOn   ############################   \n",
    "cwd = os.getcwd()\n",
    "path = cwd\n",
    "\n",
    "agg_results(path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
